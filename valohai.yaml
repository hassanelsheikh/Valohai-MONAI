- step:
    name: preprocess
    image: docker.io/python:3.10
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    command:
      - pip install -r requirements.txt
      - python preprocess.py
    inputs:
      - name: dataset
        default: https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar
        description: Input dataset as a tar/zip package
- step:
    name: train
    image: nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    command:
      - apt-get update && apt-get install -y python3-pip
      - pip3 install torch==2.7.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
      - pip3 install -r requirements.txt
      - python3 train.py {parameters}
    inputs:
      - name: preprocessed_data
        default: dataset://task03_liver/test 
        description: Preprocessed data in a zip package
    parameters:
      - name: lr
        type: float
        default: 1e-4
      - name: epochs
        type: integer
        default: 100
      - name: batch_size
        type: integer
        default: 2
      - name: in_channels
        type: integer
        default: 1
      - name: out_channels
        type: integer
        default: 3
      - name: num_res_units
        type: integer
        default: 2
      - name: channels
        type: string
        default: 16,32,64,128
        multiple-separator: ","
        multiple: separate
- step:
    name: evaluate
    image: nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    command:
      - apt-get update && apt-get install -y python3-pip
      - pip3 install torch==2.7.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
      - pip3 install -r requirements.txt
      - python3 evaluate.py
    inputs:
      - name: preprocessed_data
        default: datum://01971921-072b-4553-c48c-a86b7b056899
      - name: model
        default: datum://latest-model
- step:
    name: inference
    image: docker.io/python:3.10
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    command:
      - pip install -r requirements.txt
      - python inference.py {parameters}
    inputs:
      - name: model
        default: datum://latest-model
      - name: image
        default: datum://019711fb-eb24-fec3-001e-4da65d1bf469
    parameters:
      - name: in_channels
        type: integer
        default: 1
      - name: out_channels
        type: integer
        default: 3
      - name: num_res_units
        type: integer
        default: 2
      - name: channels
        type: string
        default: 16,32,64,128
        multiple-separator: ","
        multiple: separate
- pipeline:
    name: train_and_evaluate
    parameters:
      - name: in_channels
        targets:
          - train.parameters.in_channels
          - inference.parameters.in_channels
        default: 1
      - name: out_channels
        targets:
          - train.parameters.out_channels
          - inference.parameters.out_channels
        default: 3
      - name: num_res_units
        targets:
          - train.parameters.num_res_units
          - inference.parameters.num_res_units
        default: 2
      - name: channels
        targets:
          - train.parameters.channels
          - inference.parameters.channels
        default: 16,32,64,128
    nodes:
      - name: preprocess
        type: execution
        step: preprocess
      - name: train
        type: execution
        step: train
        override:
          inputs:
            - name: preprocessed_data
      - name: evaluate
        type: execution
        step: evaluate
        override:
          inputs:
            - name: preprocessed_data
      - name: inference
        type: execution
        step: inference
    edges:
      - [preprocess.outputs.*.zip, train.input.preprocessed_data]
      - [preprocess.outputs.*.zip, evaluate.input.preprocessed_data]
      - [train.outputs.*.pth, evaluate.input.model]
      - [train.outputs.*.pth, inference.input.model]
